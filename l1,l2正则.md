# 线性回归正则化与参数MAP估计的统一解释

## 目录索引
1. [线性回归基本模型](#1-线性回归基本模型)  
2. [最大似然估计（MLE）](#2-最大似然估计mle)  
3. [最大后验估计（MAP）](#3-最大后验估计map)  
4. [正则化与先验的对应关系](#4-正则化与先验的对应关系)  
   - [L2正则化（岭回归）与高斯先验](#l2正则化岭回归与高斯先验)  
   - [L1正则化（Lasso）与拉普拉斯先验](#l1正则化lasso与拉普拉斯先验)  
5. [关键总结对比表](#5-关键总结对比表)  
6. [超参数关系](#6-超参数关系)  

---

<a id="1-线性回归基本模型"></a>
## 1. 线性回归基本模型
模型形式：
$$
y = X\theta + \epsilon
$$
- **似然函数**（高斯噪声假设）：
$$
p(y | X, \theta) = \mathcal{N}(y | X\theta, \sigma^2 I)
$$

```python
# 生成线性回归数据点示意图
import numpy as np
import matplotlib.pyplot as plt

# 生成数据（假设单特征）
np.random.seed(42)
X = np.linspace(0, 5, 100)
theta_true = 2.0  # 真实参数
y = theta_true * X + np.random.normal(0, 1, 100)

# 绘制数据点
plt.scatter(X, y, alpha=0.6, label='观测数据')
plt.plot(X, theta_true*X, color='red', lw=2, label='真实模型 $y=2x$')
plt.xlabel('特征 $x$')
plt.ylabel('目标值 $y$')
plt.legend()
plt.title("线性回归数据与真实模型")
plt.show()
```

---

<a id="2-最大似然估计mle"></a>
## 2. 最大似然估计（MLE）
目标函数与参数解：
$$
\hat{\theta}_{\text{MLE}} = \arg\min_\theta \frac{1}{2\sigma^2} \|y - X\theta\|^2
$$
**闭式解**（矩阵形式）：
$$
\hat{\theta}_{\text{MLE}} = (X^T X)^{-1} X^T y
$$
（要求 $X^T X$ 可逆）

```python
import numpy as np
import matplotlib.pyplot as plt

# MLE参数解示意图（单变量回归）
X_design = np.c_[np.ones(100), X]  # 添加截距项
theta_mle = np.linalg.inv(X_design.T @ X_design) @ X_design.T @ y

# 绘制MLE拟合直线
plt.scatter(X, y, alpha=0.6)
plt.plot(X, theta_mle[0] + theta_mle[1]*X, color='green', lw=2, 
         label=f'MLE拟合: $y={theta_mle[0]:.2f}+{theta_mle[1]:.2f}x$')
plt.xlabel('特征 $x$')
plt.ylabel('目标值 $y$')
plt.legend()
plt.title("MLE参数估计结果")
plt.show()
```

---

<a id="3-最大后验估计map"></a>
## 3. 最大后验估计（MAP）
贝叶斯框架下的优化目标：
$$
\hat{\theta}_{\text{MAP}} = \arg\max_\theta \left[ \log p(y | X, \theta) + \log p(\theta) \right]
$$


---

<a id="4-正则化与先验的对应关系"></a>
## 4. 正则化与先验的对应关系

<a id="l2正则化岭回归与高斯先验"></a>
### L2正则化（岭回归）与高斯先验
- **高斯先验分布**：
$$
p(\theta) = \mathcal{N}(0, \tau^2 I) \quad \Rightarrow \quad \log p(\theta) \propto -\frac{1}{2\tau^2}\|\theta\|^2
$$
- **MAP目标函数**：
$$
\arg\min_\theta \left[ \frac{1}{2\sigma^2}\|y - X\theta\|^2 + \frac{1}{2\tau^2}\|\theta\|^2 \right]
$$
- **闭式解**（矩阵形式）：
$$
\hat{\theta}_{\text{MAP}} = (X^T X + \lambda I)^{-1} X^T y
$$
其中正则化系数 $\lambda = \sigma^2 / \tau^2$。

```python
# L2正则化参数空间约束与解示意图
import numpy as np
import matplotlib.pyplot as plt

# 生成参数网格
theta1, theta2 = np.meshgrid(np.linspace(-2, 5, 100), np.linspace(-2, 5, 100))

# 定义损失函数（简化的二次损失）
loss = 0.5 * ((theta1 - 1)**2 + (theta2 - 2)**2)  # 假设最优解在(1,2)

# L2约束区域（圆形）
l2_constraint = theta1**2 + theta2**2 <= 4.0

# 绘制图像
plt.figure(figsize=(8,6))
plt.contour(theta1, theta2, loss, levels=10, cmap='viridis', alpha=0.8)  # 损失等高线
plt.contourf(theta1, theta2, l2_constraint, alpha=0.2, colors='red')     # 约束区域
plt.plot(1, 2, 'ro', markersize=8, label='无约束最优解')                  # 原始解
plt.plot(0.8, 1.6, 'bx', markersize=10, label='L2约束解')               # 近似约束解
plt.xlabel(r'$\theta_1$', fontsize=12)
plt.ylabel(r'$\theta_2$', fontsize=12)
plt.title("L2正则化：球形约束与解偏移", fontsize=14)
plt.legend()
plt.grid(True)
plt.show()

```



<a id="l1正则化lasso与拉普拉斯先验"></a>
### L1正则化（Lasso）与拉普拉斯先验
- **拉普拉斯先验分布**：
$$
p(\theta) = \text{Laplace}(0, b) \quad \Rightarrow \quad \log p(\theta) \propto -\frac{1}{b}\|\theta\|_1
$$
- **MAP目标函数**：
$$
\arg\min_\theta \left[ \frac{1}{2\sigma^2}\|y - X\theta\|^2 + \frac{1}{b}\|\theta\|_1 \right]
$$
- **参数解特性**：
  - 无闭式解析解（因L1范数不可导）
  - 需使用数值方法（如坐标下降、近端梯度法）
  - 稀疏性：趋向产生部分参数为0的解,可判断那些维度几乎无作用

```python
# L1正则化参数空间约束与解示意图
import numpy as np
import matplotlib.pyplot as plt

# 生成参数网格（与L2示例相同范围）
theta1, theta2 = np.meshgrid(np.linspace(-2, 5, 100), np.linspace(-2, 5, 100))

# 定义相同的损失函数
loss = 0.5 * ((theta1 - 1)**2 + (theta2 - 2)**2)

# L1约束区域（菱形）
l1_constraint = np.abs(theta1) + np.abs(theta2) <= 3.0

# 绘制图像
plt.figure(figsize=(8,6))
plt.contour(theta1, theta2, loss, levels=10, cmap='viridis', alpha=0.8)  # 损失等高线
plt.contourf(theta1, theta2, l1_constraint, alpha=0.2, colors='blue')    # 约束区域
plt.plot(1, 2, 'ro', markersize=8, label='无约束最优解')                 # 原始解
plt.plot(0, 2.5, 'bx', markersize=10, label='L1约束解')                  # 稀疏解示例
plt.xlabel(r'$\theta_1$', fontsize=12)
plt.ylabel(r'$\theta_2$', fontsize=12)
plt.title("L1正则化：菱形约束与稀疏解", fontsize=14)
plt.legend()
plt.grid(True)
plt.show()

```

---

<a id="5-关键总结对比表"></a>
## 5. 关键总结对比表
| **正则化类型**       | **参数解形式**                         | **先验分布**                  | 闭式解存在性  | 稀疏性       |
|----------------------|----------------------------------------|-------------------------------|-------------|-------------|
| MLE（无正则化）       | $(X^T X)^{-1} X^T y$                  | 无                            | ✔️           | ✖️           |
| L2正则化（岭回归）    | $(X^T X + \lambda I)^{-1} X^T y$      | 高斯分布 $\mathcal{N}(0, \tau^2 I)$ | ✔️           | ✖️（收缩解）  |
| L1正则化（Lasso）     | 数值优化求解（坐标下降等）              | 拉普拉斯分布 $\text{Laplace}(0, b)$ | ✖️           | ✔️           |

---

<a id="6-超参数关系"></a>
## 6. 超参数关系
- **L2正则化**：$\lambda = \sigma^2 / \tau^2$
- **L1正则化**：$\lambda = \sigma^2 / b$（稀疏程度由 $b$ 控制）
